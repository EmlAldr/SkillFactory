{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ассоциативные правила."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм построения ассоциативных правил сводится к простому статистическому анализу совместной встречаемости покупок в потребительской корзине.  \n",
    "\n",
    "В общем виде ассоциативные правила  можно описать так: \n",
    "\n",
    "**«КТО КУПИЛ X, ТАКЖЕ КУПИЛ Y»**\n",
    "\n",
    "Например, простое правило может выглядеть следующим образом: «Если куплен бородинский хлеб, то будет куплено молоко \"Домик в деревне\" с вероятностью 40 %. При этом оба товара покупаются с вероятностью 3 %».\n",
    "\n",
    "В основе лежит анализ транзакций, внутри каждой из которых лежит свой уникальный itemset (например, в качестве айтемсета может выступать чек с покупками) из набора items (покупок).\n",
    "\n",
    "Набор данных для анализа можно представить следующим образом. В качестве столбцов у нас будут продукты (или какие-то ещё товары, представленные в магазине). Для каждой транзакции мы будем проставлять единицу (если товар куплен) или ноль (если товар не куплен).  В идеальном случае данные представляются именно в бинарном виде, то есть так:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/ml9_1.png\" alt=\"Binary-cross-entropy\" width=\"400\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве примера мы привели пиво и подгузники не просто так — с ними связана интересная история, иллюстрирующая силу работы ассоциативных правил.\n",
    "\n",
    "В 1992 году консалтинговая компания исследовала 1,2 миллиона транзакций в магазинах сети Osco Drug. В результате анализа ассоциативных правил самым сильным оказалось «Между 17:00 и 19:00 чаще всего пиво и подгузники покупают вместе». Такое правило показалось руководителям компании контринтуитивным, и они не стали обращать на него внимание.\n",
    "\n",
    "Однако объяснение такому правилу вскоре всё же нашлось. Когда жены отправляли мужей в ближайший магазин за подгузниками для детей, те захватывали ещё и пиво для себя.\n",
    "\n",
    "Таким образом, если бы руководство магазина полагалось бы на ассоциативные правила, а не на собственную интуицию, они могли бы поднять продажи и упростить покупателям жизнь, расположив пиво рядом с подгузниками."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При помощи специальных алгоритмов находятся те самые ассоциативные «правила» совпадения items внутри одной транзакции, которые потом сортируются по их силе.  Нам надо научиться сравнивать ассоциативные правила по их силе. Для этого введем несколько предназначенных для этого метрик.\n",
    "\n",
    "Для того чтобы сравнить ассоциативные правила по их силе (значимости) необходимо ввести несколько метрик — Support, Confidence и Lift.\n",
    "\n",
    "**SUPPORT**\n",
    "$$\\begin{equation}\\operatorname{supp}(X)=\\frac{\\{t \\in T ; X \\in t\\}}{|T|}\\end{equation}$$\n",
    "\n",
    "Здесь $X$ — это itemset, в котором находится items, $T$ — количество транзакций.\n",
    "\n",
    "Можно охарактеризовать этот показатель как индекс частоты встречаемости конкретного продукта в имеющихся транзакциях. Это для того случая, если нам интересен один конкретный продукт (item).\n",
    "\n",
    "Чаще нам бывает важно, насколько часто какие-то два продукта встречаются вместе. Для такого случая мы будем рассчитывать следующий вариант показателя:\n",
    "$$\\begin{equation}\\operatorname{supp}\\left(x_{1} \\cup x_{2}\\right)=\\frac{\\sigma\\left(x_{1} \\cup x_{2}\\right)}{|T|}\\end{equation}$$\n",
    "\n",
    "**Как считается Support?**\n",
    "\n",
    "Предположим, что  есть несколько транзакций, в которых присутствует пиво, подгузники и кола. Мы считаем количество совместных транзакций, в которых есть пиво и подгузники, и делим на общее количество транзакций. Получается, Support такого правила равен 3/5, или 60 %.\n",
    "$$\\begin{equation}s u p p=\\frac{3}{5}=60 \\%\\end{equation}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONFIDENCE**\n",
    "\n",
    "Этот показатель высчитывается на основе метрики Support.\n",
    "$$\\begin{equation}\\operatorname{conf}\\left(x_{1} \\cup x_{2}\\right)=\\frac{\\operatorname{supp}\\left(x_{1} \\cup x_{2}\\right)}{\\operatorname{supp}\\left(x_{1}\\right)}\\end{equation}$$\n",
    "\n",
    "Он определяет, как часто правило срабатывает для всего датасета.\n",
    "\n",
    "У нас есть Support пива и подгузников, которое мы посчитали. Также мы можем посчитать Support только пива. Отношение этих двух Support будет равно 3/4, или 75 %.\n",
    "$$\\begin{equation}\\operatorname{con} f=\\frac{3}{4}=75 \\%\\end{equation}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LIFT**\n",
    "\n",
    "Ещё одна метрика — Lift. Она вычисляется следующим образом:\n",
    "\n",
    "- вычисляется Support совместной встречаемости двух продуктов;\n",
    "- делится на произведение Support каждого из этих продуктов.\n",
    "\n",
    "$$\\begin{equation}\\operatorname{lift}\\left(x_{1} \\cup x_{2}\\right)=\\frac{\\sup p\\left(x_{1} \\cup x_{2}\\right)}{\\operatorname{supp}\\left(x_{1}\\right) \\times \\operatorname{supp}\\left(x_{2}\\right)}\\end{equation}$$\n",
    "\n",
    "Lift показывает, насколько items зависят друг от друга.\n",
    "$$lift=\\frac{Confidence}{Expected confidence} = \\frac{P(Подгузники | Пиво)}{P(Подгузники)}$$\n",
    "$$lift=\\frac{\\frac{3}{4}}{\\frac{3}{5}} = 1.25$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**АЛГОРИТМ APRIORI**\n",
    "\n",
    "Рассмотрим один из алгоритмов для построения ассоциативных правил — Apriori.\n",
    "\n",
    "Apriori использует следующее утверждение: \n",
    "\n",
    "если X⊆Y, то supp(X) ≥ supp(Y).\n",
    "\n",
    "Отсюда следуют два свойства:\n",
    "\n",
    "- если $X$ встречается часто, то любое подмножество X: X⊆Y также встречается часто\n",
    "- если $X$ встречается редко, то любое супермножество Y: Y ⊇X также встречается редко\n",
    "\n",
    "Древовидная структура совместной встречаемости различных продуктов.\n",
    "\n",
    "<img src=\"../images/ml9_2.png\" alt=\"Binary-cross-entropy\" width=\"600\" align=\"center\">\n",
    "<img src=\"../images/ml9_3.png\" alt=\"Binary-cross-entropy\" width=\"700\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apriori по уровням проходит по префиксному дереву и рассчитывает частоту встречаемости подмножеств  в . \n",
    "\n",
    "Таким образом:\n",
    "\n",
    "- исключаются редкие подмножества и все их супермножества.\n",
    "- рассчитывается supp(X) для каждого подходящего кандидата  размера  на уровне .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Плюс**\n",
    "\n",
    "Получаем красивый граф связей между покупками продуктов.\n",
    "<img src=\"../images/ml9_4.png\" alt=\"Binary-cross-entropy\" width=\"700\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Минусы**\n",
    "\n",
    "- Можем рекомендовать только старые товары.\n",
    "- Не всегда можем получить требуемое число рекомендаций."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Коллаборативная фильтрация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## МАТРИЦА ПРЕДПОЧТЕНИЙ\n",
    "\n",
    "Расположим в матрице клиентов по строкам, а продукты — по столбцам. На пересечении строк и столбцов разметим оценку клиентов на эти продукты.  То есть первый клиент поставил второму товару 3, а третий клиент поставил первому товару 2 и так далее.\n",
    "\n",
    "<img src=\"../images/ml9_5.png\" alt=\"Binary-cross-entropy\" width=\"400\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## КЛАСТЕРИЗАЦИЯ ПОЛЬЗОВАТЕЛЕЙ\n",
    "\n",
    "Далее мы можем применить алгоритм кластеризации для того, чтобы объединить людей.\n",
    "Выберем условную меру схожести пользователей по их истории оценок:\n",
    "$$\\begin{equation}\\operatorname{sim}(u, v)\\end{equation}$$\n",
    "\n",
    "Объединим пользователей в группы (кластеры): \n",
    "$$\\begin{equation}u \\mapsto F(u)\\end{equation}$$\n",
    "\n",
    "Разбиваем их на кластеры так, чтобы похожие пользователи оказались в одном кластере, а непохожие — в разных.\n",
    "\n",
    "Оценку пользователя объекту будем предсказывать как среднюю оценку кластера этому объекту:\n",
    "$$\\hat{r_{ui}}=\\frac{1}{\\left | F(u) \\right |}\\sum_{\\upsilon \\epsilon F(u)}^{ }r_{\\upsilon i}$$\n",
    "\n",
    "Итак, у нас есть пользователь, и у нас спрашивают, как он оценил данный фильм. Мы смотрим на кластер пользователя. Смотрим оценки пользователей из этого кластера на этот фильм (оценки тех пользователей, которые смотрели этот фильм и поставили оценку). Берем их и усредняем. Это и есть предсказание оценки фильма для нашего пользователя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проблемы алгоритма:**\n",
    "\n",
    "- Нечего рекомендовать новым/нетипичным пользователям. Если у нас появляется пользователь, который не похож ни на кого, то мы не знаем, в какой кластер его отнести. Конечно, мы первоначально относим его в какой-то случайный кластер, но рекомендации в таком случае будут плохие.\n",
    "- Не учитывается специфика каждого пользователя. По сути, мы выявляем некоторые шаблонные паттерны поведения и предпочтений, и для каждого паттерна выделяем свои рекомендации. Но на самом деле, все пользователи немного отличаются друг от друга даже в одном кластере, поэтому возникают неточности.\n",
    "- Если в кластере никто не оценивал объект, то предсказание сделать не получится."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USER-BASED\n",
    "\n",
    "Для того, чтобы преодолеть эти сложности, можно обратиться к другому алгоритму, который позволяет уйти от решения задачи кластеризации — User-based.\n",
    "\n",
    "В этом алгоритме мы заменяем жесткую кластеризацию на следующую формулу:\n",
    "$$\\begin{equation}\\hat{r}_{u i}=\\bar{r}_{u}+\\frac{\\sum_{v \\in U_{i}} \\operatorname{sim}(u, v)\\left(r_{v i}-\\bar{r}_{v}\\right)}{\\sum_{v \\in U_{i}} \\operatorname{sim}(u, v)}\\end{equation}$$\n",
    "\n",
    "Разберемся с обозначениями, которые используются в этой формуле:\n",
    "\n",
    "- $\\bar{r}_{u}$ — средняя оценка пользователя u\n",
    "- $\\bar{r}_{v}$ — средняя оценка пользователя v\n",
    "\n",
    "Средняя оценка пользователя никак не привязана к его интересам. По сути, это просто показатель того, как в среднем пользователь привык оценивать фильмы.\n",
    "\n",
    "Оценка пользователя $\\hat{r}_{u i}$, которую мы предсказываем для него, состоит из двух частей:\n",
    "\n",
    "- Непосредственно его средняя оценка.\n",
    "- Слагаемое, состоящее из: $r_{v i}-\\bar{r}_{v}$ — разница в оценках с другими пользователями, т. е. похожесть пользователей. Эта разница домножается на похожесть пользователей. То есть в числителе оказалась средневзвешенная разница в оценках. А в знаменателе находится сумма показателей схожести.\n",
    "\n",
    "По каждому клиенту подбираем релевантный для него товар в рамках группы клиентов, но не решаем задачу кластеризации, а усредняем интересы данной группы в дистанции нескольких соседей.\n",
    "\n",
    "Здесь мы руководствуемся по сути идеей, что видео можно порекомендовать человеку, если оно понравится его друзьям."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ITEM-BASED\n",
    "\n",
    "Однако, если мы транспонируем матрицу предпочтений и будем решать ту же самую задачу не в рамках клиентов, а в рамках items, то мы получим более устойчивое решение.\n",
    "$$\\begin{equation}\\hat{r}_{u i}=\\bar{r}_{i}+\\frac{\\sum_{j \\in I_{u}} \\operatorname{sim}(i, j)\\left(r_{u j}-\\bar{r}_{j}\\right)}{\\sum_{j \\in I_{u}} \\operatorname{sim}(i, j)}\\end{equation}$$\n",
    "\n",
    "По формуле (которая очень похожа на формулу из предыдущего подхода) можно понять, что этот подход симметричен и использует ту же самую идею. Только теперь у нас не пользователи похожи, а объекты (items) похожи.\n",
    "\n",
    "То есть, если мы говорим о рекомендации фильмов, то мы теперь рекомендуем пользователю фильм, который похож на те фильмы, которые уже понравились этому пользователю ранее.\n",
    "\n",
    "Кроме того, у нас будет больше размерность на каждый вектор items, чем размерность вектора клиентов по items. За счёт этого будет больше оценок, выше статистическая значимость и модель будет более устойчива к переобучению. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Преимущества**\n",
    "\n",
    "- Меньше размерность матрицы расстояний\n",
    "- Легче вычислять\n",
    "- Модель более устойчива к переобучению\n",
    "- Можно реже обновлять\n",
    "- Меньше подвержены изменению предпочтений со временем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Недостатки**\n",
    "\n",
    "- Проблема холодного старта\n",
    "- Плохие предсказания для новых/нетипичных пользователей/объектов\n",
    "- Тривиальность рекомендаций\n",
    "- Ресурсоемкость вычислений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

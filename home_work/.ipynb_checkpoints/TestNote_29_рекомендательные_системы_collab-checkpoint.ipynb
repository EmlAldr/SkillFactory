{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Коллаборативная фильтрация. Практика\n",
    "\n",
    "Продолжим работать с датасетом Netflix.\n",
    "\n",
    "Примечание: так как предобработка датасета занимает большое время, мы сделали её за вас! Готовый датасет можно найти здесь.\n",
    "\n",
    "Также вам понадобятся данные с ID и названиями фильмов, которые можно найти здесь.\n",
    "\n",
    "Если вам интересно самостоятельно обработать данные с самого начала, то можете скачать датасет, приложенный к уроку, и выполнить шаги, изложенные в скринкасте. Они также прописаны в приложенном к уроку ноутбуке.\n",
    "https://www.kaggle.com/netflix-inc/netflix-prize-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Подготовить данные самому**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = []\n",
    "for i in range(4):\n",
    "    data = pd.read_csv('/home/aprosvetov/netflix/combined_data_' + str(i+1)+'.txt', header = None, names = ['Cust_Id', 'Rating'], usecols = [0,1])\n",
    "    data_all.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset shape: (100498277, 2)\n",
      "-Dataset examples-\n",
      "           Cust_Id  Rating\n",
      "0               1:     NaN\n",
      "5000000    2560324     4.0\n",
      "10000000   2271935     2.0\n",
      "15000000   1921803     2.0\n",
      "20000000   1933327     3.0\n",
      "25000000   1465002     3.0\n",
      "30000000    961023     4.0\n",
      "35000000   1372532     5.0\n",
      "40000000    854274     5.0\n",
      "45000000    116334     3.0\n",
      "50000000    768483     3.0\n",
      "55000000   1331144     5.0\n",
      "60000000   1609324     2.0\n",
      "65000000   1699240     3.0\n",
      "70000000   1776418     4.0\n",
      "75000000   1643826     5.0\n",
      "80000000    932047     4.0\n",
      "85000000   2292868     4.0\n",
      "90000000    932191     4.0\n",
      "95000000   1815101     3.0\n",
      "100000000   872339     4.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "df.index = np.arange(0,len(df))\n",
    "print('Full dataset shape: {}'.format(df.shape))\n",
    "print('-Dataset examples-')\n",
    "print(df.iloc[::5000000, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df_nan = pd.DataFrame(pd.isnull(df.Rating))\n",
    "df_nan = df_nan[df_nan['Rating'] == True]\n",
    "df_nan = df_nan.reset_index()\n",
    "\n",
    "movie_np = []\n",
    "movie_id = 1\n",
    "\n",
    "for i,j in zip(df_nan['index'][1:],df_nan['index'][:-1]):\n",
    "    # numpy approach\n",
    "    temp = np.full((1,np.abs(i-j-1)), movie_id)\n",
    "    movie_np = np.append(movie_np, temp)\n",
    "    movie_id += 1\n",
    "\n",
    "# Account for last record and corresponding length\n",
    "# numpy approach\n",
    "last_record = np.full((1,len(df) - df_nan.iloc[-1, 0] - 1),movie_id)\n",
    "movie_np = np.append(movie_np, last_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[pd.notnull(df['Rating'])]\n",
    "\n",
    "df['Movie_Id'] = movie_np.astype(int)\n",
    "df['Cust_Id'] = df['Cust_Id'].astype(int)\n",
    "print('-Dataset examples-')\n",
    "print(df.sample(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/srv/aprosvetov/netflix/data_prep.csv', sep=';', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Взять уже подготовленные данные**\n",
    "\n",
    "Подготовленные данные в data_fin.csv, но 100 млн.строк юпитер не может прочитать, падает ядро. Почистил файл и оставил 30 млн. data_fin_half.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 501 dialout 1806696634 Aug 22 17:26 data_fin.csv\r\n",
      "-rw-r--r--  1 501 dialout  566312581 Aug 22 17:56 data_fin_half.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la ../data/ | grep data_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/data_fin_half.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5096"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Movie_Id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "476784"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Cust_Id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмём подвыборку из 10000 случайных кастомеров и 5000 фильмов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_sample = df.Cust_Id.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_sample = df.Movie_Id.sample(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для генерации простых рекомендаций с помощью коллаборативной фильтрации можно воспользоваться модулем surprise. Загрузим в модуль surprise наш датасет с помощью метода Reader. \n",
    "\n",
    "Предварительно необходимо установить модуль surprise, он не является предустановленным.\n",
    "\n",
    "Это можно сделать через pip. В случае, если это не работает, можно воспользоваться одним из следующих четырёх вариантов:\n",
    "- conda install -c conda-forge scikit-surprise\n",
    "- conda install -c conda-forge/label/gcc7 scikit-surprise\n",
    "- conda install -c conda-forge/label/cf201901 scikit-surprise\n",
    "- conda install -c conda-forge/label/cf202003 scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting surprise\n",
      "  Downloading https://files.pythonhosted.org/packages/61/de/e5cba8682201fcf9c3719a6fdda95693468ed061945493dea2dd37c5618b/surprise-0.1-py2.py3-none-any.whl\n",
      "Collecting scikit-surprise\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/37/5d334adaf5ddd65da99fc65f6507e0e4599d092ba048f4302fe8775619e8/scikit-surprise-1.1.1.tar.gz (11.8MB)\n",
      "\u001b[K     |████████████████████████████████| 11.8MB 23.7MB/s eta 0:00:01   |████████████████████████▎       | 8.9MB 3.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-surprise->surprise) (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.11.2 in /opt/conda/lib/python3.6/site-packages (from scikit-surprise->surprise) (1.17.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /notebooks/home/.local/lib/python3.6/site-packages (from scikit-surprise->surprise) (1.5.4)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from scikit-surprise->surprise) (1.12.0)\n",
      "Building wheels for collected packages: scikit-surprise\n",
      "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.1-cp36-cp36m-linux_x86_64.whl size=1752527 sha256=9013b9791f8e9259dff73893cdeb4607003be7db2197042fce5ea3c9baee9917\n",
      "  Stored in directory: /notebooks/home/.cache/pip/wheels/78/9c/3d/41b419c9d2aff5b6e2b4c0fc8d25c538202834058f9ed110d0\n",
      "Successfully built scikit-surprise\n",
      "Installing collected packages: scikit-surprise, surprise\n",
      "\u001b[33m  WARNING: The script surprise is installed in '/notebooks/home/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed scikit-surprise-1.1.1 surprise-0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --user surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, импортируем установленную библиотеку и приступаем к работе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем только те оценки, которые относятся к выбранному подмножеству кастомеров и только те оценки, которые относятся к выбранному подмножеству фильмов. Именно в такой последовательности — сначала Cust_Id, затем Movie_Id, затем Rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "data = Dataset.load_from_df(df[df.Cust_Id.isin(cust_sample) &\n",
    "                              df.Movie_Id.isin(movie_sample)][['Cust_Id', 'Movie_Id', 'Rating']], reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В модуле surprise есть несколько реализаций коллаборативной фильтрации. Мы возьмем одну из самых самых простых — принцип ближайших соседей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Принцип коллаборативной фильтрации заключается в следующем:\n",
    "\n",
    "Для каждого человека находится небольшое множество похожих на него зрителей с оценками примерно такими же, какие поставил человек на ряд фильмов (item). Из этой группы можно усреднить оценки на просмотренные фильмы и для тех членов группы, у которых ещё не было просмотров этих фильмов экстраполировать значения оценок в этих ячейках.\n",
    "\n",
    "Таким образом, у нас появляется некая средняя оценка в группе для каждого фильма из просмотренных, и мы можем предположить, что тем людям, которые ещё не успели посмотреть эти фильмы, они понравятся."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как размерность по пользователям больше, чем размерность по фильмам, то выгоднее использовать не user-based алгоритм, а item-based. В этом случае вектор будет состоять не из оценок одного пользователя на различные фильмы, а будет содержать все оценки фильма от многих пользователей. Таким образом мы получим больший вектор, но само количество векторов будет меньше. А если меньше количество векторов, то проще посчитать матрицу из взаимной дистанции.\n",
    "\n",
    "Именно это мы задаем в качестве параметров алгоритма:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNBasic\n",
    "\n",
    "sim_options = {\n",
    "    'name': 'cosine',\n",
    "    'user_based': False\n",
    "}\n",
    " \n",
    "knn = KNNBasic(sim_options=sim_options)\n",
    "trainingSet = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запускаем алгоритм и формирует датасет для тренировки специальной функцией build_full_trainset().\n",
    "\n",
    "После этого проводим тренировку модели на сформированном тренировочном датасете:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x7fcf281fe160>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(trainingSet)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью натренированной модели мы можем проскорить остальные оценки. Для этого сгенерируем тестовый сет и построим предсказание по этому датасету:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSet = trainingSet.build_anti_testset()\n",
    "predictions = knn.test(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = pd.read_csv('movie_titles.csv', encoding = \"ISO-8859-1\", \n",
    "                     header = None, \n",
    "                     names = ['Movie_Id', 'Year', 'Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Prediction(uid=2503129, iid=44, r_ui=3.5881227434677645, est=4.474997108906492, details={'actual_k': 40, 'was_impossible': False}),\n",
       " Prediction(uid=2503129, iid=47, r_ui=3.5881227434677645, est=3.9245326082785117, details={'actual_k': 40, 'was_impossible': False}),\n",
       " Prediction(uid=2503129, iid=76, r_ui=3.5881227434677645, est=4.424598056472339, details={'actual_k': 40, 'was_impossible': False}),\n",
       " Prediction(uid=2503129, iid=83, r_ui=3.5881227434677645, est=4.374795599566862, details={'actual_k': 40, 'was_impossible': False})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат получился не удобочитаемым. Поэтому давайте сделаем вспомогательную функцию, которая будет брать топ-3 фильмов и их оценки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    " \n",
    "def get_top3_recommendations(predictions, topN = 3):\n",
    "     \n",
    "    top_recs = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_recs[uid].append((iid, est))\n",
    "     \n",
    "    for uid, user_ratings in top_recs.items():\n",
    "        user_ratings.sort(key = lambda x: x[1], reverse = True)\n",
    "        top_recs[uid] = user_ratings[:topN]\n",
    "     \n",
    "    return top_recs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обрабатываем наше предсказание:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_recommendations = get_top3_recommendations(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью следующей функции переведем тексты фильмов в удобочитаемый вид, то есть раскодируем заглавия фильмов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def print_recs(i):\n",
    "    for (a, b) in top3_recommendations[i]:\n",
    "        print(titles[titles.Movie_Id == a]['Name'].values[0], np.round(b,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью этой функции выведем рекомендации для случайного пользователя:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Blair Witch Project 4.65\n",
      "Lone Wolf and Cub: Sword of Vengeance 4.63\n",
      "The Basketball Diaries 4.63\n"
     ]
    }
   ],
   "source": [
    "i = 262149\n",
    "print_recs(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family Guy: Vol. 1: Seasons 1-2 4.32\n",
      "Family Guy: Vol. 2: Season 3 4.32\n",
      "Team America: World Police 4.3\n"
     ]
    }
   ],
   "source": [
    "i = np.random.choice(list(top3_recommendations.keys()))\n",
    "\n",
    "print_recs(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим, что смотрел этот человек, и выберем из нашего датасета те фильмы, которые этот человек оценил на 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['The Deer Hunter', 'Dogma', 'Kill Bill: Vol. 2',\n",
       "       'The Matrix: Revolutions', 'Boyz N the Hood',\n",
       "       'Dragon: The Bruce Lee Story', 'The Sandlot', 'Man on Fire',\n",
       "       'Hook', 'Casino: 10th Anniversary Edition',\n",
       "       'Die Hard 2: Die Harder', \"Cheech & Chong's Up in Smoke\",\n",
       "       'Lord of the Rings: The Fellowship of the Ring', 'Braveheart',\n",
       "       'Elf', 'Half Baked', 'Lost: Season 1',\n",
       "       'Fear and Loathing in Las Vegas', 'The Matrix: Reloaded', 'Signs',\n",
       "       'Patch Adams', 'Army of Darkness',\n",
       "       'South Park: Passion of the Jew', 'Mission: Impossible',\n",
       "       'Tommy Boy', 'Jay and Silent Bob Strike Back',\n",
       "       'Jackass: The Movie',\n",
       "       'Star Wars: Episode V: The Empire Strikes Back',\n",
       "       'GoodFellas: Special Edition', 'Snatch', 'Fight Club',\n",
       "       'Scarface: 20th Anniversary Edition', 'Awakenings', 'Michael',\n",
       "       'The Cable Guy', 'Natural Born Killers',\n",
       "       'Lord of the Rings: The Two Towers: Extended Edition',\n",
       "       'The Lord of the Rings: The Fellowship of the Ring: Extended Edition',\n",
       "       'Blade', 'Super Troopers', 'All About the Benjamins',\n",
       "       'Murder in the First', 'The Evil Dead', 'Star Trek: Nemesis',\n",
       "       'Rounders', 'Good Will Hunting', 'Terminator 2: Extreme Edition',\n",
       "       'The Chronicles of Riddick', 'Friday',\n",
       "       'The Exorcist: Restored Version',\n",
       "       'Beavis and Butt-head Do America', 'Die Hard',\n",
       "       'Searching for Bobby Fischer', 'Akira', 'Waterworld',\n",
       "       'Pulp Fiction', 'American History X', 'Far and Away',\n",
       "       'Forrest Gump', 'Lord of the Rings: The Two Towers',\n",
       "       \"White Men Can't Jump\", 'The Boondock Saints', 'Office Space',\n",
       "       'Gladiator', \"Donnie Darko: Director's Cut\",\n",
       "       'Lord of the Rings: The Return of the King', 'The Patriot',\n",
       "       'The Shawshank Redemption: Special Edition', 'South Park: Bigger',\n",
       "       'Die Hard With a Vengeance', 'The Matrix', 'Beetlejuice',\n",
       "       'Dead Poets Society',\n",
       "       'Lord of the Rings: The Return of the King: Extended Edition',\n",
       "       'City Slickers', 'Zoolander', 'Band of Brothers',\n",
       "       'The Big Lebowski', 'The Running Man', 'Amadeus', 'Raw',\n",
       "       'The Sopranos: Season 1', 'Demolition Man',\n",
       "       'Star Wars: Episode IV: A New Hope', 'Planet of the Apes',\n",
       "       'The Green Mile', 'Blow', 'Tombstone', 'Donnie Darko',\n",
       "       'South Park: Winter Wonderland', 'Meet the Parents',\n",
       "       \"The Devil's Advocate\", 'Saving Private Ryan', 'Full Metal Jacket',\n",
       "       'Tomorrow Never Dies'], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "films = data.df[(data.df.Cust_Id == i) & (data.df.Rating == 5)]['Movie_Id'].values\n",
    "titles[titles.Movie_Id.isin(films)]['Name'].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error, f1_score, accuracy_score, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Линейная регрессия. Реализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_boston()\n",
    "data['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Реализация линейной регрессии с использованием матричных операций"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия выражается следующей зависимостью:\n",
    "$$y=X\\theta+\\epsilon,$$\n",
    "где $X$ — матрица объекты-признаки, $y$ — вектор целевых значений, соответствующих $X$, $\\theta$ — параметр линейной регрессии, $\\epsilon$ — некоторый шум."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из данного следует выражение для $\\theta$ как:\n",
    "$$X^Ty=X^TX\\theta \\rightarrow \\theta=(X^TX)^{-1}X^Ty$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем выражение для $\\theta$ с помощью операций линейной алгебры библиотеки Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЗАДАЧА Реализовать функцию, осуществляющую матричные операции для получения theta\n",
    "# def linreg_linear(X, y):\n",
    "    \n",
    "#     return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовить данные\n",
    "\n",
    "X, y = data['data'], data['target']\n",
    "\n",
    "X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычислить параметр theta\n",
    "theta = linreg_linear(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14,)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сделать предсказания для тренировочной выборки\n",
    "y_pred = X.dot(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_regression_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f'MSE = {mse:.2f}, RMSE = {rmse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 21.89, RMSE = 4.68\n"
     ]
    }
   ],
   "source": [
    "# Посчитать значение ошибок MSE и RMSE для тренировочных данных\n",
    "print_regression_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбить выборку на train/valid, вычислить theta,\n",
    "# сделать предсказания и посчитать ошибки MSE и RMSE\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
    "theta = linreg_linear(X_train, y_train)\n",
    "y_pred = X_valid.dot(theta)\n",
    "y_train_pred = X_train.dot(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 24.50, RMSE = 4.95\n",
      "MSE = 21.59, RMSE = 4.65\n"
     ]
    }
   ],
   "source": [
    "print_regression_metrics(y_valid, y_pred)\n",
    "print_regression_metrics(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 21.89, RMSE = 4.68\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X,y)\n",
    "y_pred = lr.predict(X)\n",
    "print_regression_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Реализация линейной регрессии с использованием методов оптимизации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для реализации линейной регрессии с помощью методов оптимизации будем использовать функцию ошибки **среднего квадратичного** ([Mean Squared Error](https://en.wikipedia.org/wiki/Mean_squared_error)), которая является выпуклой функцией в n-мерном пространстве $\\mathbb{R}^n$ и в общем виде выглядит следующим образом:\n",
    "$$MSE = \\frac{1}{n} * \\sum_{i=1}^{n}{(y_i - a(x_i))^2}.$$\n",
    "Здесь $x_i$ — вектор-признак $i$-го объекта обучающей выборки, $y_i$ — истинное значение для $i$-го объекта, $a(x)$ — алгоритм, предсказывающий для данного объекта $x$ целевое значение, $n$ — кол-во объектов в выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае линейной регрессии $MSE$ представляется как:\n",
    "$$MSE(X, y, \\theta) = \\frac{1}{2n} * \\sum_{i=1}^{n}{(y_i - \\theta^Tx_i)^2} = \\frac{1}{2n} \\lVert{y - X\\theta}\\rVert_{2}^{2}=\\frac{1}{2n} (y - X\\theta)^T(y - X\\theta),$$\n",
    "где $\\theta$ — параметр модели линейной регрессии, $X$ — матрица объекты-признаки, $y$ - вектор истинных значений, соответствующих $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем первый вариант представления функции ошибки и посчитаем ее градиент по параметру $\\theta$, предварительно переименовав $MSE$ в $L$:\n",
    "$$L=\\frac{1}{2n} * \\sum_{i=1}^{n}{(y_i - \\theta^Tx_i)^2}$$\n",
    "$$\\nabla L = \\frac{1}{n}\\sum_{i=1}^{n}{(\\theta^Tx_i - y_i) \\cdot x_i} = \\frac{1}{n}X^T(X\\theta - y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходя из полученного выражения градиента, реализуем алгоритм градиентного спуска:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализовать функцию вычисления градиента функции MSE\n",
    "\n",
    "def calc_mse_gradient(X, y, theta):\n",
    "    n = X.shape[0]\n",
    "    grad = 1. / n * X.transpose().dot(X.dot(theta) - y)\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализовать функцию, осуществляющую градиентный шаг\n",
    "# (функция должна содержать параметр величины шага alpha - learning rate)\n",
    "\n",
    "def gradient_step(theta, theta_grad, alpha):\n",
    "    return theta - alpha * theta_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализовать функцию цикла градиентного спуска с доп. параметрами\n",
    "# начального вектора theta и числа итераций\n",
    "\n",
    "def optimize(X, y, grad_func, start_theta, alpha, n_iters):\n",
    "    theta = start_theta.copy()\n",
    "    \n",
    "    for i in range(n_iters):\n",
    "        theta_grad = grad_func(X, y, theta)\n",
    "        theta = gradient_step(theta, theta_grad, alpha)\n",
    "    \n",
    "    return theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбить таблицу данных на матрицы X и y\n",
    "X, y = data['data'], data['target']\n",
    "\n",
    "# Добавить фиктивный столбец единиц (bias линейной модели)\n",
    "X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])\n",
    "m = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оптимизировать параметр линейной регрессии theta на всех данных\n",
    "theta = optimize(X, y, calc_mse_gradient, np.ones(m), 0.001, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.41647399e+246, 3.32349992e+247, 7.39564172e+247, 8.96295209e+247,\n",
       "       5.07578059e+245, 4.22030567e+246, 4.63094053e+247, 5.29083888e+248,\n",
       "       2.65643383e+247, 8.19991211e+247, 3.27135991e+249, 1.38363846e+248,\n",
       "       2.64323053e+249, 9.88835598e+247])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.    ,  88.9762, 100.    ,  27.74  ,   1.    ,   0.871 ,\n",
       "         8.78  , 100.    ,  12.1265,  24.    , 711.    ,  22.    ,\n",
       "       396.9   ,  37.97  ])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверить максимальные значения по каждому признаку в данных\n",
    "X.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n",
      "168.3704950393814\n"
     ]
    }
   ],
   "source": [
    "print(data['feature_names'][np.argmax(X.std(axis=0)) + 1])\n",
    "print(np.max(X.std(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализовать даннные с помощью стандартной нормализации\n",
    "X, y = data['data'], data['target']\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 9.9339306 , 3.80423444, 2.42256516, 3.66839786,\n",
       "       2.73234648, 3.55504427, 1.11749449, 3.96051769, 1.66124525,\n",
       "       1.79819419, 1.63882832, 0.44105193, 3.54877081])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Добавить фиктивный столбец единиц (bias линейной модели)\n",
    "X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])\n",
    "X.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оптимизировать theta на новых данных\n",
    "theta = optimize(X, y, calc_mse_gradient, np.ones(m), 0.01, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.25328063e+01, -9.21740195e-01,  1.07033639e+00,  1.06388396e-01,\n",
       "        6.86667316e-01, -2.05006416e+00,  2.68062168e+00,  1.40667969e-02,\n",
       "       -3.10608483e+00,  2.57511475e+00, -1.97802851e+00, -2.05725099e+00,\n",
       "        8.48690321e-01, -3.74025884e+00])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сделать предсказания при полученных параметрах\n",
    "y_pred = X.dot(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 21.90, RMSE = 4.68\n"
     ]
    }
   ],
   "source": [
    "# Посчитать значение ошибок MSE и RMSE для тренировочных данных\n",
    "print_regression_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 20.44, RMSE = 4.52\n"
     ]
    }
   ],
   "source": [
    "# Разбить выборку на train/valid, оптимизировать theta,\n",
    "# сделать предсказания и посчитать ошибки MSE и RMSE\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
    "theta = optimize(X_train, y_train, calc_mse_gradient, np.ones(m), 0.01, 5000)\n",
    "y_pred = X_valid.dot(theta)\n",
    "\n",
    "print_regression_metrics(y_valid, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

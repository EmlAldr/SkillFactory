{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Что такое воспроизводимость?\n",
    "\n",
    "Если сравнивать рабочий процесс обычного software-разработчика и специалиста по анализу данных, можно найти ряд принципиальных различий. Код, разрабатываемый дата-сайентистом, должен быть воспроизводим в постоянно меняющихся в условиях:\n",
    " - Меняются данные, поступающие на вход.\n",
    " - Трансорфмируются пайплайны препроцессинга данных.\n",
    " - Постоянно изменяются гиперпараметры алгоритмов.\n",
    " \n",
    "В идеале, от процесса работы ожидается, что выполнение кода должно приводить к одинаковым результатам в различных условиях. Воспроизводимость результатов является одним из главных показателей качества вашей модели. Именно поэтому обеспечение воспроизводимости является одной из важнейших проблем в современном ML-инжиниринге.\n",
    "\n",
    "Мы можем доверять результату, полученному с помощью модели, только когда доподлинно известно, на какой выборке и с каким пайплайном предобработки она была построена. Кроме того, ожидается, что результаты будут консистентными, так как необходимо однозначно понимать какое изменение привело к улучшению или ухудшению результатов.\n",
    "\n",
    "## РАБОТА В КОМАНДЕ\n",
    "\n",
    "Наиболее остро вопрос воспроизводимости поднимается в случае, если над одной моделью работает большая data science-команда. Каждый участник команды должен воспроизвести весь пайплайн и получить тот же самый результат. При этом возможные изменения должны доставляться в общий код так же быстро, сохраняя все требования к воспроизводимости.\n",
    "\n",
    "## УПРАВЛЕНИЕ ВЕРСИЯМИ\n",
    "\n",
    "На рисунке приведен классический пайплайн работы над моделью. Обычно весь пайплайн представлен в виде частей кода, для работы с которым используется распределенная система управления версиями Git.\n",
    "\n",
    "В процессе работы над проектом порождаются различные артефакты: датасеты, модели, файлы конфигураций и прочее. Для их версионирования обычно используются такие инструменты, как DVC и Nexus sonatype.\n",
    "\n",
    "## НАСТРОЙКА ОКРУЖЕНИЯ И СРЕДЫ ВЫПОЛНЕНИЯ\n",
    "\n",
    "Одним из важнейших аспектов воспроизводимости является настройка окружения. Необходимо обеспечить одинаковые ОС, установить все зависимости и одинаковые версии библиотек. Чтобы обеспечить единообразие среды выполнения, прибегают к инструментам изоляции и контейнеризации, таким как Docker. Об этих инструментах подробнее будет рассказано в следующих модулях.\n",
    "\n",
    "## УПРАВЛЕНИЕ ЭКСПЕРИМЕНТАМИ\n",
    "\n",
    "Для каждого запуска обучения необходимо фиксировать настройки гиперпараметров и сохранять их, в чем помогают системы управления экспериментами, например, MLFlow.\n",
    "\n",
    "Стоит отметить, что на текущий момент в индустрии не сформировался единый стандарт к обеспечению воспроизводимости. Над созданием универсального решения бьются многие крупные компании. \n",
    "\n",
    "На практике вы тоже неоднократно встречались с этой проблемой, например в заданиях в рамках обучения Data Science — когда вас просили фиксировать random-seed для обеспечения воспроизводимости. К тому же при обучении моделей вам нужно однозначно понимать, как изменение в коде повлияло на изменение метрики качества. \n",
    "\n",
    "Когда вы начнете работать в DS-команде, того же самого будут требовать от вас ваши коллеги. Обычно, чем крупнее компания, тем более серьезные требования к воспроизводимости необходимо обеспечить. Причём, как было отмечено выше, так как нет сформировавшегося стандарта, пути и используемые инструменты могут кардинально отличаться в разных компаниях. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Офлайн- и онлайн-модели\n",
    "\n",
    "В самом начале мы говорили о том, что модель в вакууме никому не нужна — она приносит пользу только если встроена в какой-то бизнес-процесс. От того, как выглядит этот процесс, зависит и то, как нужно встраивать туда модель. Давайте разберём самые частые примеры. \n",
    "\n",
    "Принципиально модели можно разделить на два типа: офлайн и онлайн.\n",
    "\n",
    "**Определения: онлайн- и офлайн-модель**\n",
    "\n",
    "Онлайн-модель, или модель, доступная в реальном времени, подразумевает, что существует некий постоянный процесс с этой моделью. К этому процессу можно делать запросы, чтобы получить предсказание модели. Эти запросы могут делать люди, а могут делать и другие процессы. Важно, что в такой схеме предсказание можно получить сразу, как только инициатору запроса это требуется.\n",
    "\n",
    "Офлайн-схема работает иначе: модель не доступна для запросов, а наоборот, запускается один раз на всех доступных на текущий момент данных и может делать это с некоторой периодичностью.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте разберем несколько примеров в порядке увеличения автоматизации.\n",
    "\n",
    "0. СОРЕВНОВАНИЯ НА KAGGLE\n",
    "\n",
    "Самый простой пример офлайн-модели, которая не требует никакой автоматизации — соревнования по анализу данных. Действительно, оставляя за скобками само построение модели, когда она уже есть у вас на руках, вы один раз применяете её ко всем тестовым данным и заливаете очередной сабмит с результатами. Тут нечего автоматизировать, потому что модель применяется только один раз.\n",
    "\n",
    "1. ОТЧЁТ\n",
    "\n",
    "Вы проводите некоторое исследование на основе данных и обучаете предсказательную модель для отчета. Тут тоже, скорее всего, не нужна никакая автоматизация, потому что ценность представляют не сами предсказания модели, а их интерпретация и в целом весь отчёт.\n",
    "\n",
    "При этом не факт, что модель будет применена единожды — вас могут позже попросить сделать расчёт на новых данных, возможно, даже будут просить делать его каждый день — и это уже ближе к следующему примеру.\n",
    "\n",
    "2. РАСЧЁТЫ ПО РАСПИСАНИЮ\n",
    "\n",
    "Такой формат уже гораздо ближе к реальным задачам.\n",
    "\n",
    "Обычно это выглядит так: есть настроенный процесс, который загружает новые данные за прошедший интервал времени, и вам нужно применить модель к этим данным. \n",
    "\n",
    "Скорее всего, в этом процессе человек уже не участвует, а значит и результаты должны не просто посчитаться, а куда-то записаться, чтобы быть доступными для следующего участника процесса.\n",
    "\n",
    "Разберем два примера — простой (✮) и сложный (✮✮). Начнём с простого. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Уровень 1. Рекомендации для небольшого онлайн-магазина**\n",
    "\n",
    "Почему используем именно офлайн-схему? Причин может быть много, например, так дешевле и проще. Оставим это за скобками, но стоит отметить, что даже во многих крупных компаниях пока что делают именно так.\n",
    "\n",
    "Итак, простой кейс. Вы построили рекомендательную систему для вашего небольшого магазина. Для её работы вам нужны данные о продажах, которые лежат в вашей небольшой, как и магазин, базе данных. В таком случае, вам достаточно написать скрипт, который:\n",
    "\n",
    "1. Будет выгружать данные из базы, например в файл .csv.\n",
    "\n",
    "2. Читать этот файл.\n",
    "\n",
    "3. Загружать вашу модель и прогонять её на обновленных данных.\n",
    "\n",
    "4. Результаты записывать обратно в базу в соответствующие таблицы. \n",
    "\n",
    "Итак, нам необходимо запускать скрипт каждый день в определенное время. Пусть это будет 12 часов вечера, когда активности уже нет.\n",
    "\n",
    "Для решения этой задачи существуют так называемые шедулеры — процессы, которые умеют по расписанию запускать другие процессы, например наш скрипт. Для базовой версии нам подойдет самый простой и популярный. Он называется cron и встроен во все UNIX-системы (в том числе MacOS). \n",
    "\n",
    "❗ Надеемся, что вам никогда не придется столкнуться с продакшеном на другой ОС, всё-таки стандарт индустрии — UNIX. Но если это произошло, не всё потеряно: есть свои планировщики и в Windows, либо можно отдельно установить cron, используя cygwin.\n",
    "\n",
    "Cron устроен очень просто. Вам нужно просто добавить строчку с расписанием вашей задачи в специальный файл. Сделать это можно, набрав команду: **crontab -e**\n",
    "\n",
    "Синтаксис записи довольно простой и состоит из расписания и команды. Команда — это обычная bash-команда, а расписание — это пять чисел или символов. По порядку они означают минуты, часы, дни месяца, месяц и день недели, когда нужно выполнить задание. Можно указать число из нужного диапазона или * для любого значения. \n",
    "\n",
    "Например, вот такая запись: **10 0 * * * echo hi >> file.txt**\n",
    "\n",
    "будет дописывать hi в файл в 0 часов 10 минут любого дня любого месяца в любой день недели, то есть по сути ежедневно. \n",
    "\n",
    "☕ Не беспокойтесь, всё это запоминать необязательно. Перед тем, как это написать, авторам самим пришлось погуглить.\n",
    "\n",
    "Подробнее прочитать про Cron и более продвинутые возможности синтаксиса можно на Википедии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Уровень 2. Большой магазин**\n",
    "\n",
    "Теперь представим, что магазин у вас большой, и такой наивный подход уже не сработает. Данные у вас лежат в распределенной файловой системе на кластере, обрабатывать их тоже нужно, используя распределенные инструменты. В таком случае стоит использовать более сложные шедулеры, например Airflow, который позволяет запускать несколько задач и задавать зависимости между ними. Например, что запуск модели должен произойти только после успешной предобработки данных, а предобработка запускается только после того, как загрузились сырые данные. Также Airflow умеет мониторить задачи, удобно показывает логи и много других мелочей. \n",
    "\n",
    "Также бывают ситуации, когда модель не работает сама по себе, а встраивается в существующий фреймворк для параллельной обработки данных. В таком случае мы будем использовать Spark. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3. ОНЛАЙН\n",
    "\n",
    "Теперь перейдем к онлайну, и вы увидите, что существует принципиальная разница между двумя моделями.\n",
    "\n",
    "Для примера возьмем условного Telegram-бота, в который можно прислать фото. Его наша модель обработает и выдаст ответ: скажем, изображен ли на фото хот-дог или нет. В этом случае мы не можем запускать обработку раз в сутки, потому что пользователь ожидает увидеть ответ сразу. Но в простом случае и нам не нужно иметь дел с базами и прочим — мы просто поднимаем сервис, в который backend бота может кинуть картинку, а он прогонит модель и вернет бэкенду результат.\n",
    "\n",
    "4. МОНИТОРИНГ РАБОТЫ МОДЕЛИ\n",
    "\n",
    "В более сложном случае нам недостаточно просто залить модель на сервис и забыть о ней. Нужно настроить мониторинг ошибок сервиса, уметь с минимальным даунтаймом обновлять модель, писать логи запросов и ответов и множество других мелочей. Тому, как правильно это делать, и будут посвящены следующие главы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

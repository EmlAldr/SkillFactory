# Credit Scoring

Проект был выполнен на платформе kaggle.com в рамках соревнования [Credit Scoring](https://www.kaggle.com/c/sf-dst-scoring)
Основной ноутбук - **sf-credit-scoring-emelyanovan.ipynb**

## Цeли и задачи проекта:
**Цель проекта** - предсказать дефолт клиента 

**Задачи**:

 - Подготовить набор данных для обучения модели
 - Потренировать работу с pandas на реальных данных
 - Попрактиковаться в EDA
 - Попрактиковаться в построении модели, в определении оптимальных гиперпарамтров для нее
 - Попрактиковаться в работе с несбалансированной выборкой и методами работы с ней
 - Добавить к портфолио на Github еще один проект.

## Краткая информация о данных:
Исходный набор данных содержит:

- Анкетная информация по 73799 клиентам  и факт наличия дефолта у них
- Условия проживания описаны в виде 6 номинативных признаков и 13 (включая наличие дефолта) количественных признаков.
- Количественные признаки практически не содержат выбросов.
- Только один из признаков содержит пропуски.

## Этапы работы:

- Загрузка данных
- Определение вспомогательных функций
- Проход по всем номинативным признакам:
    - определение лишних значений, которые не предусмотрены описанием признака, и очистка данных от них
    - опредение пустых значений и заполнение их
    - перекодирование значений признаков в числовой тип
- Проход по всем количественным признакам:
    - определение лишних значений, которые не предусмотрены описанием признака или являются выбросами, и очистка данных от них
    - опредение пустых значений и заполнение их
- Проведение корреляционного анализа для количественных признаков
- Очистка данных от признаков с высоким коээфициентом корреляции
- Проверка на значимость колличественных переменны
- Проверка на значимость категориальных и бинарных переменн
- Очистка от признаков, в которых не найдены статистически значимые различия 
- Подготовка данных для модели:
    - Стандартизация числовых признаков
    - OneHotEncoding подход к категориальным признакам
    - Удаление ненужных признаков
    - Разбиение на тестовую и валидационную выборку
- Построение логистической модели
- Оценка качества модели
- Кросс-валидация
- Получение промежуточных данных
- Поиск оптимальных гиперпараметров
- Правка изначчальной выборки данных - undersampling и oversampling методами
- Выбор наилучшей модели
- Подведение итогов

## Ответы на вопросы саморефлексии:
1. **Какова была ваша роль в команде?** - Команды нет, вся работа была выполнена мной. 

2. **Какой частью своей работы вы остались особенно довольны?**  - В целом доволен проделанной работой. 

3. **Что не получилось сделать так, как хотелось? Над чем ещё стоит поработать?** - На проект у меня было мало времени. Работа выполнена, но итоговый результат по метрике модели RO_AUC получился не очень большим в рамках соревнования. Думаю, причина в построении новых признаков. Также не успел оформить построенную модель и этапы обработки входных данных в виде классов. 

4. **Что интересного и полезного вы узнали в этом модуле?** - Самостоятельно поработал с логистической моделью, подбирал гипертаматры для нее. Поработал с библиотеками, которые реализуют  undersampling и oversampling методы для работы с несбалансированными выборками.

5. **Что является вашим главным результатом при прохождении этого проекта?** - Получил практику построения моделей. 

6. **Какие навыки вы уже можете применить в текущей деятельности?** - пока что никаких.

7. **Планируете ли вы дополнительно изучать материалы по теме проекта?** - пока что нет.
